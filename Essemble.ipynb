{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading Olivetti faces from https://ndownloader.figshare.com/files/5976027 to C:\\Users\\fabio\\scikit_learn_data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((400, 4096), (400,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "X, y = fetch_olivetti_faces(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 4096), (100, 4096), (300,), (100,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, random_state=42)\n",
    "X_tr.shape, X_te.shape, y_tr.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True, False, False,  True, False,  True,\n",
       "         True,  True,  True, False, False,  True,  True, False,  True,\n",
       "        False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        False,  True, False,  True,  True, False,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False]),\n",
       " 0.83)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testando o classificador KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "modelo = KNeighborsClassifier()\n",
    "modelo.fit(X_tr, y_tr)\n",
    "knn_pr = modelo.predict(X_te)\n",
    "knnhits = knn_pr == y_te\n",
    "knnhits, sum(knnhits)/len(knnhits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True, False,  True, False,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        False,  True,  True,  True, False,  True, False,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True, False,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        False]),\n",
       " 0.81)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testando com outros classificadores\n",
    "# Naive bayes da UCI\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "modelo = GaussianNB()\n",
    "modelo.fit(X_tr, y_tr)\n",
    "gnb_pr = modelo.predict(X_te)\n",
    "gnbhits = gnb_pr == y_te\n",
    "gnbhits, sum(gnbhits)/len(gnbhits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True, False,  True,  True, False, False,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "        False,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True, False,  True,  True,\n",
       "        False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        False, False,  True,  True,  True,  True, False,  True, False,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True, False,  True,  True,\n",
       "        False]),\n",
       " 0.78)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testando com o classificador perceptrom\n",
    "from sklearn.linear_model import Perceptron\n",
    "modelo = Perceptron()\n",
    "modelo.fit(X_tr, y_tr)\n",
    "per_pr = modelo.predict(X_te)\n",
    "perhits = per_pr == y_te\n",
    "perhits, sum(perhits)/len(perhits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True, False, False],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True, False],\n",
       "       [ True, False,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True, False,  True],\n",
       "       [ True,  True,  True],\n",
       "       [False,  True,  True],\n",
       "       [False,  True, False],\n",
       "       [ True,  True,  True],\n",
       "       [False,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True, False,  True],\n",
       "       [False,  True,  True],\n",
       "       [False,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True, False],\n",
       "       [False,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True, False],\n",
       "       [ True, False,  True],\n",
       "       [ True,  True, False],\n",
       "       [ True,  True,  True],\n",
       "       [False,  True, False],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True, False,  True],\n",
       "       [ True,  True, False],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True, False,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True, False],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [False,  True,  True],\n",
       "       [ True,  True, False],\n",
       "       [ True,  True,  True],\n",
       "       [ True, False,  True],\n",
       "       [False, False, False],\n",
       "       [ True,  True,  True],\n",
       "       [False,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True, False, False],\n",
       "       [False,  True,  True],\n",
       "       [ True, False,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [False, False, False],\n",
       "       [ True,  True, False],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True, False, False],\n",
       "       [ True,  True,  True],\n",
       "       [False, False, False],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True, False],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True, False,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True, False],\n",
       "       [ True, False,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True, False],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [False, False, False]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "hits = np.stack((knnhits, gnbhits, perhits))\n",
    "hits.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20, 20, 20],\n",
       "       [28, 28, 28],\n",
       "       [ 3,  3,  3],\n",
       "       [21, 21, 21],\n",
       "       [ 9,  9,  9],\n",
       "       [ 8,  8,  8],\n",
       "       [32, 32, 32],\n",
       "       [ 9,  9,  9],\n",
       "       [26, 26, 26],\n",
       "       [12, 16, 28],\n",
       "       [ 0,  0,  0],\n",
       "       [36, 36, 36],\n",
       "       [ 5,  5,  8],\n",
       "       [ 7, 15,  7],\n",
       "       [13, 13, 13],\n",
       "       [ 4, 34, 29],\n",
       "       [25, 27, 25],\n",
       "       [37, 37, 37],\n",
       "       [23, 23, 23],\n",
       "       [38, 38, 38],\n",
       "       [ 7, 15,  7],\n",
       "       [ 1,  1,  1],\n",
       "       [ 4, 39, 39],\n",
       "       [25, 27, 25],\n",
       "       [ 0,  0,  0],\n",
       "       [ 3, 39, 39],\n",
       "       [11, 11, 11],\n",
       "       [22, 22, 22],\n",
       "       [26, 26, 26],\n",
       "       [10, 15, 10],\n",
       "       [29, 39, 39],\n",
       "       [29, 19, 19],\n",
       "       [26, 26, 26],\n",
       "       [ 5,  5, 29],\n",
       "       [20, 23, 23],\n",
       "       [11, 11, 11],\n",
       "       [12, 39, 11],\n",
       "       [20, 34, 34],\n",
       "       [15, 15, 15],\n",
       "       [14, 14, 14],\n",
       "       [38, 38, 38],\n",
       "       [ 5,  5, 29],\n",
       "       [ 7,  9,  7],\n",
       "       [ 2,  2, 36],\n",
       "       [ 8,  8,  8],\n",
       "       [28, 38, 28],\n",
       "       [14, 14, 14],\n",
       "       [18, 18, 18],\n",
       "       [ 2,  2,  2],\n",
       "       [17, 39, 17],\n",
       "       [ 4,  4, 39],\n",
       "       [32, 32, 32],\n",
       "       [33, 33, 33],\n",
       "       [ 7,  9,  7],\n",
       "       [37, 37, 37],\n",
       "       [ 3,  3,  1],\n",
       "       [22, 22, 22],\n",
       "       [17, 17, 17],\n",
       "       [ 3,  3,  3],\n",
       "       [ 0, 15, 15],\n",
       "       [12, 12, 36],\n",
       "       [29, 29, 29],\n",
       "       [25, 16, 25],\n",
       "       [17, 35, 28],\n",
       "       [10, 10, 10],\n",
       "       [14,  3,  3],\n",
       "       [35, 35, 35],\n",
       "       [26, 12,  1],\n",
       "       [37, 39, 39],\n",
       "       [ 7,  9,  7],\n",
       "       [32, 32, 32],\n",
       "       [14, 14, 14],\n",
       "       [ 3, 35, 20],\n",
       "       [ 4,  4,  8],\n",
       "       [38, 38, 38],\n",
       "       [24, 24, 24],\n",
       "       [22, 22, 22],\n",
       "       [36, 36, 36],\n",
       "       [17,  9, 28],\n",
       "       [28, 28, 28],\n",
       "       [16, 16, 20],\n",
       "       [ 1,  1,  1],\n",
       "       [20, 20,  8],\n",
       "       [25, 25, 25],\n",
       "       [27, 27, 27],\n",
       "       [ 6,  6,  6],\n",
       "       [24, 24, 24],\n",
       "       [30, 30, 30],\n",
       "       [10, 15, 10],\n",
       "       [ 9,  9,  9],\n",
       "       [23, 23, 23],\n",
       "       [33, 33, 33],\n",
       "       [11, 11, 11],\n",
       "       [22, 22,  8],\n",
       "       [18, 25, 18],\n",
       "       [31, 31, 31],\n",
       "       [37, 37, 39],\n",
       "       [38, 38, 38],\n",
       "       [23, 23, 23],\n",
       "       [17,  9, 18]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pr = np.stack((knn_pr, gnb_pr, per_pr))\n",
    "y_pr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True, False,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False]),\n",
       " 0.91)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMBINAÇÃO DOS CLASSIFICADORES\n",
    "from scipy import stats\n",
    "y_pr = stats.mode(y_pr)[0][0]\n",
    "vohits = y_pr == y_te  #acertos do hits\n",
    "vohits, sum(vohits)/len(vohits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinação de classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True, False,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False]),\n",
       " 0.91)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "modelo = VotingClassifier([\n",
    "('knn', KNeighborsClassifier()),\n",
    "('naivebayes', GaussianNB()),\n",
    "('perceptron', Perceptron())\n",
    "])\n",
    "modelo.fit(X_tr, y_tr)\n",
    "vo_pr = modelo.predict(X_te)\n",
    "vohits = vo_pr == y_te\n",
    "vohits, sum(vohits)/len(vohits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True, False,  True,  True, False,  True,\n",
       "         True,  True,  True,  True, False, False,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        False,  True,  True,  True, False, False,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True, False,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False]),\n",
       " 0.82)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificar se o classificador é bom ou ruim usando uma arvore de decisao e comparando a acurácia\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "modelo = VotingClassifier([\n",
    "('knn', KNeighborsClassifier()),\n",
    "('naivebayes', GaussianNB()),\n",
    "('arvore', DecisionTreeClassifier())\n",
    "])\n",
    "modelo.fit(X_tr, y_tr)\n",
    "vo_pr = modelo.predict(X_te)\n",
    "vohits = vo_pr == y_te\n",
    "vohits, sum(vohits)/len(vohits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o knn faz 83 sozinho, junto com a arvore de decisões ele cai para 81\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True, False,  True,  True, False,  True,  True,  True,\n",
       "        False, False,  True,  True, False, False, False, False, False,\n",
       "         True, False,  True, False, False, False, False, False, False,\n",
       "        False,  True, False, False,  True, False, False, False, False,\n",
       "        False, False,  True, False, False,  True, False, False,  True,\n",
       "        False, False,  True, False,  True, False,  True,  True, False,\n",
       "         True, False, False, False,  True,  True,  True,  True, False,\n",
       "        False, False,  True,  True, False, False, False,  True, False,\n",
       "        False, False,  True,  True, False, False, False,  True, False,\n",
       "        False, False,  True, False,  True,  True, False, False,  True,\n",
       "         True,  True,  True,  True,  True, False, False,  True, False,\n",
       "        False]),\n",
       " 0.4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testando a arvore sozinha \n",
    "modelo = DecisionTreeClassifier(random_state=42)\n",
    "modelo.fit(X_tr, y_tr)\n",
    "dt_pr = modelo.predict(X_te)\n",
    "dthits = dt_pr == y_te\n",
    "dthits, sum(dthits)/len(dthits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conclusão: a arvore de decisões sozinha é um classificador ruim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diversificação por reamostragem\n",
    "# solução: implementar o algoritmo Baggin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        False, False,  True,  True, False,  True, False, False,  True,\n",
       "         True,  True, False,  True, False, False,  True, False,  True,\n",
       "         True,  True,  True, False,  True,  True,  True, False, False,\n",
       "        False,  True, False, False, False,  True, False,  True, False,\n",
       "         True,  True,  True,  True, False, False,  True,  True, False,\n",
       "         True, False, False, False,  True,  True,  True,  True, False,\n",
       "        False,  True, False,  True, False,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        False]),\n",
       " 0.64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "modelo = BaggingClassifier(random_state=42)\n",
    "modelo.fit(X_tr, y_tr)\n",
    "bgg_pr = modelo.predict(X_te)\n",
    "bgghits = bgg_pr == y_te\n",
    "bgghits, sum(bgghits)/len(bgghits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesmo um classificador ruim, ele pode se tornar melhor estando \n",
    "# junto com vários classificadores bons\n",
    "# aumentando a aleatoriedade aumenta a diversidade, como faz isso? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True, False, False,  True,\n",
       "         True,  True,  True, False,  True, False,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True, False,  True, False,  True, False,  True,  True,\n",
       "        False,  True,  True, False,  True, False,  True,  True, False,\n",
       "         True, False, False,  True, False,  True,  True,  True, False,\n",
       "        False,  True, False,  True,  True, False, False,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True]),\n",
       " 0.72)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = BaggingClassifier(DecisionTreeClassifier(splitter='random'), random_state=42)\n",
    "modelo.fit(X_tr, y_tr)\n",
    "bgg_pr = modelo.predict(X_te)\n",
    "bgghits = bgg_pr == y_te\n",
    "bgghits, sum(bgghits)/len(bgghits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.72 = aumento de acurácia ficou melhor com o aleatório\n",
    "# aumentar o numero de árvores também melhora a acurácia,\n",
    "# o agoritmo bagg ja tem um padrão de 10 arvores, no proximo codigo \n",
    "# vamos criar 100 arvores: n_estimaters=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True, False,  True,  True,  True,  True,  True, False,\n",
       "        False,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False]),\n",
       " 0.89)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = BaggingClassifier(DecisionTreeClassifier(splitter='random'), \n",
    "n_estimators=100, random_state=42)\n",
    "modelo.fit(X_tr, y_tr)\n",
    "bgg_pr = modelo.predict(X_te)\n",
    "bgghits = bgg_pr == y_te\n",
    "bgghits, sum(bgghits)/len(bgghits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acurácia melhorou mas ainda não chegou na combinação dos três primeiros\n",
    "# Random Forest é um bagging de Arvores de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True, False,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        False,  True,  True,  True,  True, False, False,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True]),\n",
       " 0.88)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelo = RandomForestClassifier(random_state=42)\n",
    "modelo.fit(X_tr, y_tr)\n",
    "rf_pr = modelo.predict(X_te)\n",
    "rfhits = rf_pr == y_te\n",
    "rfhits, sum(rfhits)/len(rfhits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultado parecido porém de forma mais rápida\n",
    "# como regularizar o baggin? limitando as caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True, False,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True]),\n",
       " 0.94)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = BaggingClassifier(DecisionTreeClassifier(splitter='random'), \n",
    "n_estimators=100, max_features=0.15, random_state=42) # gerando over fit # para cada arvore ele esta usando 15% de cada caracteristica e o treinamento foi mais rápido\n",
    "modelo.fit(X_tr, y_tr)\n",
    "bgg_pr = modelo.predict(X_te)\n",
    "bgghits = bgg_pr == y_te\n",
    "bgghits, sum(bgghits)/len(bgghits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para cada arvore ele esta usando 15% de cada caracteristica e o treinamento foi mais rápido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Florestas extremamente aleatórias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True]),\n",
       " 0.95)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "modelo = ExtraTreesClassifier(random_state=42)\n",
    "modelo.fit(X_tr, y_tr)\n",
    "et_pr = modelo.predict(X_te)\n",
    "ethits = et_pr == y_te\n",
    "ethits, sum(ethits)/len(ethits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# um resultado um pouco melhor\n",
    "# outra forma é aplicar o algoritmo boosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False, False, False, False, False, False,  True, False, False,\n",
       "        False, False, False,  True, False, False, False, False, False,\n",
       "        False,  True, False, False, False, False, False, False, False,\n",
       "        False, False,  True, False,  True, False,  True, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "         True, False,  True, False, False, False,  True, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False,  True, False,\n",
       "        False, False,  True, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False,  True, False, False, False, False,  True, False,\n",
       "        False]),\n",
       " 0.13)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "modelo = AdaBoostClassifier(random_state=42)\n",
    "modelo.fit(X_tr, y_tr)\n",
    "aboos_pr = modelo.predict(X_te)\n",
    "abooshits = aboos_pr == y_te\n",
    "abooshits, sum(abooshits)/len(abooshits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustar as caracteristicas para aumentar a acurácia:\n",
    "# ele depende de ajustes e parâmetros pois sozinho tenho desempenho baixo\n",
    "# um ajuste que pode ser feito é o max_depht profundidade maxima da arvore\n",
    "# outro é o splitter randomico\n",
    "# taxa de aprendizado: learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True, False,\n",
       "        False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True]),\n",
       " 0.91)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "modelo = AdaBoostClassifier(DecisionTreeClassifier(max_depth=25,\n",
    "splitter='random'), learning_rate=0.15, random_state=42)\n",
    "modelo.fit(X_tr, y_tr)\n",
    "aboos_pr = modelo.predict(X_te)\n",
    "abooshits = aboos_pr == y_te\n",
    "abooshits, sum(abooshits)/len(abooshits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o teste melhorou porque os parâmetros foram superajustados mas\n",
    "# não funcionaria se fosse jogar direto em um ambiente de produção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'XGBClassifier' from 'xgboost' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4336/1311450071.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Algoritmo Xgboost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodelo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muse_lebel_encoder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'XGBClassifier' from 'xgboost' (unknown location)"
     ]
    }
   ],
   "source": [
    "# Algoritmo Xgboost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "modelo = XGBClassifier(use_lebel_encoder=False, random_state=42)\n",
    "modelo.fit(X_tr, y_tr)\n",
    "xgbs_pr = modelo.predict(X_te)\n",
    "xgbshits = xgbs_pr == y_te\n",
    "xgbshits, sum(xgbshits)/len(xgbshits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'XGBclassifier' from 'xgboost' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4336/110287813.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBclassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m modelo = XGBClassifier(colsemple_bynode=0.01, learn_rate=0.15,\n\u001b[0;32m      6\u001b[0m random_state=42)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'XGBclassifier' from 'xgboost' (unknown location)"
     ]
    }
   ],
   "source": [
    "# ajustar as característica do xgboost\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBclassifier\n",
    "modelo = XGBClassifier(colsemple_bynode=0.01, learn_rate=0.15,\n",
    "random_state=42)\n",
    "modelo.fit(X_tr, y_tr)\n",
    "xgbs_pr = modelo.predict(X_te)\n",
    "xgbshits = xgbs_pr == y_te\n",
    "xgbshits, sum(xgbshits)/len(xgbshits) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ativar xgboost?\n",
    "# ultimo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True]),\n",
       " 0.95)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# algoritmo Stacking com ajustes \n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "voting = VotingClassifier([\n",
    "('knn', KNeighborsClassifier()),\n",
    "('naivebayes', GaussianNB()),\n",
    "('perceptron', Perceptron())\n",
    "])\n",
    "\n",
    "modelo = StackingClassifier([\n",
    "('voting', voting),\n",
    "('extratrees', ExtraTreesClassifier(random_state=42)),\n",
    "('randomforest', RandomForestClassifier(random_state=42))\n",
    "], cv=3, passthrough=True)\n",
    "modelo.fit(X_tr, y_tr)\n",
    "sc_pr = modelo.predict(X_te)\n",
    "schits = sc_pr == y_te\n",
    "schits, sum(schits)/len(schits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# com o cv=3 o resultado foi pior, para ver se melhora usei o passthrough=True e isso melhorou para 95%"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a5cd576f049c40808befa6b86db46ed2a04adf484378ead481f8d7a8b894f57"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
